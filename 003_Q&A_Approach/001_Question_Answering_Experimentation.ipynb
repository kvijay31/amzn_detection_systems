{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# purpose: \n",
    "Experimentation with multiple question answering modules on sample reviews which have been tagged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "# USE-\n",
    "from  transformers  import  AutoTokenizer, AutoModelWithLMHead, pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_name = \"MaRiOrOsSi/t5-base-finetuned-question-answering\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelWithLMHead.from_pretrained(model_name)\n",
    "question = \"does the text speak about reviews?\"\n",
    "context = \"42 is the answer to life, the universe and everything\"\n",
    "# context = \"I bought this product based on the high rating, but it turned out to be completely different from what I expected. The rating must be misleading.\"\n",
    "# context = \" I am totally convinced the good reviews are fake. This by far being one of the worst movies I have ever seen. What a horrible story line I was so bored. The cast stands outside for part of this movie, while people disappear, they argue. Then they move into the lodge and the rest of the cast disappears. That's it that's the movie, no explanation, no climax , just a poorly written script . That is how it ends just with nothing that what they give you. I don't even understand the whole point of this story because there was none. I don't think anyone could ever give this a good review.‚Äù \n",
    "# context = \"I am totally convinced the good reviews are fake. This by far being one of the worst movies I have ever seen. What a horrible story line I was so bored\"\n",
    "input = f\"question: {question} context: {context}\"\n",
    "encoded_input = tokenizer([input],\n",
    "                             return_tensors='pt',\n",
    "                             max_length=512,\n",
    "                             truncation=True)\n",
    "output = model.generate(input_ids = encoded_input.input_ids,\n",
    "                            attention_mask = encoded_input.attention_mask)\n",
    "output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "life, the universe, and everything\n"
     ]
    }
   ],
   "source": [
    "# question = \"Is the text talking about misleading rating?\"\n",
    "question = 'what is spoken about?'\n",
    "context = \"42 is the answer to life, the universe and everything\"\n",
    "# context = \"I bought this product based on the high rating, but it turned out to be completely different from what I expected. The rating must be misleading.\"\n",
    "# context = 'ratings are bad'\n",
    "input = f\"question: {question} context: {context}\"\n",
    "encoded_input = tokenizer([input],\n",
    "                             return_tensors='pt',\n",
    "                             max_length=512,\n",
    "                             truncation=True)\n",
    "output = model.generate(input_ids = encoded_input.input_ids,\n",
    "                            attention_mask = encoded_input.attention_mask)\n",
    "output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is not talking about misleading ratings.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "# text = \"In recent years, there has been a growing concern about the accuracy of rating systems. Many believe that these ratings are misleading and do not accurately reflect the quality of products or services. This has led to calls for increased regulation of these systems to ensure that consumers are not misled.\"\n",
    "text = \"I bought this product based on the high rating, but it turned out to be completely different from what I expected. The rating must be misleading.\"\n",
    "\n",
    "question = \"Is the text talking about ratings?\"\n",
    "\n",
    "encoded_dict = tokenizer.encode_plus(question, text, return_tensors='pt', max_length=512)\n",
    "input_ids = encoded_dict['input_ids']\n",
    "attention_mask = encoded_dict['attention_mask']\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids, attention_mask)\n",
    "    answer = tokenizer.decode(output[0].argmax(dim=-1).tolist()[0])\n",
    "\n",
    "if \"Yes\" in answer:\n",
    "    print(\"The text is talking about misleading ratings.\")\n",
    "else:\n",
    "    print(\"The text is not talking about misleading ratings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the above cell, misclassification can be witnessed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> not_duplicate</s>\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# load the T5 tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-large')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-large')\n",
    "\n",
    "# define the input question and context\n",
    "\n",
    "question = \"Is the text talking about ratings?\"\n",
    "text = \"I bought this product based on the high rating, but it turned out to be completely different from what I expected. The rating must be misleading.\"\n",
    "\n",
    "# context = \"France is a country located in Western Europe. Its capital is Paris.\"\n",
    "\n",
    "# tokenize the input question and context\n",
    "input_string = f\"answer: {question} context: {context}\"\n",
    "input_ids = tokenizer.encode(input_string, return_tensors='pt')\n",
    "\n",
    "# generate an answer using the model\n",
    "outputs = model.generate(input_ids=input_ids)\n",
    "answer = tokenizer.decode(outputs[0])\n",
    "\n",
    "# print the generated answer\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence is not relevant to the topic.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# load the BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# define the topic and sentence to check\n",
    "topic = [\"reviews\", 'fake reviews', 'misleading reviews', 'misleading ratings']\n",
    "# context = \"Machine learning is a subfield of artificial intelligence.\"\n",
    "context =' Finally, I noticed that some of the five star reviewers are personal friends or relatives of the authors, which makes me wonder about the credibility there.'\n",
    "# context = \"I bought this product based on the high rating, but it turned out to be completely different from what I expected. The rating must be misleading.\"\n",
    "# context = 'I consider myself an open minded reader, a person of varying tastes and a patience to learn or understand different approaches to the art of literature.But this book? Oh my days, could you say anymore words and manage to get nowhere with a narrative.90 pages in and I barely understood what was going on, no narrative flow and too much filler. Was this man drunk or high when he wrote this? Were the reviewers also somewhat inebriated? Surely bothNot for me, probably not for you either. As another Amazon review said - Painful.'\n",
    "# tokenize the sentence and topic using the tokenizer\n",
    "inputs = tokenizer.encode_plus(context, topic, add_special_tokens=True, return_tensors='pt')\n",
    "\n",
    "# use the model to generate a prediction for the relevance of the sentence to the topic\n",
    "outputs = model(**inputs)\n",
    "prediction = torch.argmax(outputs.logits)\n",
    "\n",
    "# print the prediction (0 for not relevant, 1 for relevant)\n",
    "if prediction == 1:\n",
    "    print(\"The sentence is relevant to the topic.\")\n",
    "else:\n",
    "    print(\"The sentence is not relevant to the topic.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U.S. has several regulations on misleading ratings, including on the back of the productQuestion: why was the warning label on the back and not on the front?Context: should be on the front of the product just as the nutrition labelAnswer: you don't want to put warning labels on the front of the product, since you want to sell itQuestion: so why not put it on the side/back/bottom?Context: you want to put it on\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import re\n",
    "\n",
    "# Set up the OpenAI API credentials\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Define the question and context\n",
    "# question = \"What is the capital of France?\"\n",
    "# context = \"France is a country located in Western Europe. Its capital is Paris.\"\n",
    "\n",
    "# context = \"just read it realms of layers etc i like it only one of a kind\"\n",
    "# context = 'an amazing array of photographs and knowledge the hubble has given us this is an excellent story of some really great achievements '\n",
    "context = \"product is not misleading\"\n",
    "question = \"yes/no is there anything spoken about misleading ratings in the text?\"\n",
    "\n",
    "# Use the Davinci engine to generate the answer\n",
    "response = openai.Completion.create(\n",
    "    engine=\"davinci\",\n",
    "    prompt=f\"Question: {question}\\nContext: {context}\\nAnswer:\",\n",
    "    max_tokens=100,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# Extract the answer from the response\n",
    "answer = response.choices[0].text.strip()\n",
    "\n",
    "# Remove any unwanted characters from the answer\n",
    "answer = re.sub(r'[\\n\\t]+', '', answer)\n",
    "\n",
    "# Print the answer\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above uses the OpenAI API to generate an answer to a question based on a given context. It sets up the OpenAI API credentials and defines the question and context variables.\n",
    "\n",
    "To generate the answer, it makes a request to the OpenAI API using the openai.Completion.create() method. The prompt includes the question and context, and the response is generated using the Davinci engine. The max_tokens, n, stop, and temperature parameters are used to control the response generation.\n",
    "\n",
    "The generated answer is extracted from the response and stored in the answer variable. The code then removes any unwanted characters from the answer using regular expressions. Finally, the answer is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input prompt\n",
    "input_prompt = \"Context: I am totally convinced the good reviews are fake. This by far being one of the worst movies I have ever seen. What a horrible story line I was so bored. The cast stands outside for part of this movie, while people disappear, they argue. Then they move into the lodge and the rest of the cast disappears. That's it that's the movie, no explanation, no climax , just a poorly written script .. Question: Is there a mention of fake reviews?\"\n",
    "\n",
    "# Define the parameters for the API call\n",
    "parameters = {\n",
    "  'model': 'davinci',\n",
    "  'prompt': input_prompt,\n",
    "  'max_tokens': 100,\n",
    "  'temperature': 0.6,\n",
    "  'n': 1,\n",
    "  'stop': None\n",
    "}\n",
    "\n",
    "# Make the API call\n",
    "response = openai.Completion.create(**parameters)\n",
    "\n",
    "# Extract the answer from the API response\n",
    "answer = response.choices[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Posted: Jul 25, 2014 - 9:11 PM By: Mr. Marshall (Member)\\n\\nI think you\\'re confusing that movie with another one.\\n\\n\\n\\nI\\'m not sure. I saw it on Netflix and I thought it was called \"The Strangers\".\\n\\n\\n\\nIt is not the one I am thinking of, because I saw that one awhile back and I didn\\'t like it either.\\n\\n\\n\\nThe one I saw recently was about a husband and wife'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Notebook!\n"
     ]
    }
   ],
   "source": [
    "print(\"End of Notebook!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
