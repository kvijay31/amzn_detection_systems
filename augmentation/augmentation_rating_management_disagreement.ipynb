{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose: \n",
    "\n",
    "Data augmentation for rating management explicit and disagreement with ratings training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "import nlpaug.augmenter.word.context_word_embs as aug\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "tqdm.pandas()\n",
    "# Load the English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "disagreement_df = pd.read_csv('/Users/kartikvijay/Documents/MADS/Thesis pt.2/augmentation/train_dataset_disagreement_with_ratings.csv')\n",
    "rating_management_df = pd.read_csv('/Users/kartikvijay/Documents/MADS/Thesis pt.2/augmentation/training_rating_management_explicit_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44, 29, 35,  0, 76, 45, 71, 11, 14, 87, 26, 26, 86, 52, 86,  5, 30,\n",
       "       51, 92, 95, 17,  6,  2, 36, 65, 80, 85, 35, 39, 89, 13, 52, 49, 86,\n",
       "       98, 69, 73, 76, 25, 84, 12, 92, 51, 97, 20, 72, 81, 81, 90, 91, 11,\n",
       "       32, 17, 12, 65, 72, 35, 87,  7, 66, 74, 71, 19, 74, 70, 23, 85, 11,\n",
       "       11, 70, 55, 78, 65, 28, 96, 44, 87, 47, 54, 95, 73, 78, 73, 81, 57,\n",
       "       62, 17, 31, 95, 41, 79, 77, 17, 48, 11, 95, 22, 76, 17, 27, 44, 59,\n",
       "       11, 92, 64, 63, 45,  1, 19, 25, 63, 26, 72, 61,  6, 79, 12, 25, 63,\n",
       "       52, 79,  1, 73, 26, 60,  2, 83,  9,  0, 73, 58, 98, 48, 38, 51, 23,\n",
       "        7, 12, 39, 69, 84, 37, 15, 29, 16, 21, 70, 11, 63, 71, 51, 24, 58,\n",
       "       67, 53, 64, 98, 22, 30, 54, 29, 59, 38, 12, 31, 23, 66, 65, 84, 61,\n",
       "       81, 12, 12, 44, 33, 72, 44, 68, 51, 96, 52, 56, 65,  0, 40, 43, 11,\n",
       "       72,  3, 58, 77, 67, 21, 82, 52,  4, 92, 73, 25, 78])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.randint(0, 100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the ContextualWordEmbsAug class from the nlpaug library to perform text augmentation. Specifically, it is creating two instances of the ContextualWordEmbsAug class:\n",
    "\n",
    "# augmenter_sub is initialized with the model path 'roberta-base' and the action \"substitute\". This means that it will use the RoBERTa model to substitute words in the text with similar words.\n",
    "\n",
    "# augmenter_insert is initialized with the model path 'roberta-base' and the action \"insert\". This means that it will use the RoBERTa model to insert words into the text.\n",
    "\n",
    "# These augmenters can be used to generate variations of text data by replacing or inserting words using the contextual information from the RoBERTa model.\n",
    "\n",
    "augmenter_sub = aug.ContextualWordEmbsAug(model_path='roberta-base', action=\"substitute\")\n",
    "augmenter_insert = aug.ContextualWordEmbsAug(model_path='roberta-base', action=\"insert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_sentence(text, augmenter): \n",
    "    \"\"\"Augments a sentence by substituting or inserting words using the given augmenter.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input sentence to be augmented.\n",
    "        augmenter (nlpaug.augmenter.word.ContextualWordEmbsAug): The augmenter object used for augmentation.\n",
    "\n",
    "    Returns:\n",
    "        str: The augmented sentence.\n",
    "    \"\"\"\n",
    "    # Process the text with the spacy model\n",
    "    doc = nlp(text)\n",
    "    new_sent = ''\n",
    "    for sent in doc.sents: \n",
    "        # begin augmentation of each sentence\n",
    "        # print(sent.text)\n",
    "        # print('-----------------------')\n",
    "        augmented_text= augmenter.augment(sent.text)\n",
    "        print(augmented_text[0])\n",
    "        new_sent= new_sent+ ' '+ augmented_text[0] \n",
    "    return new_sent\n",
    "\n",
    "def augmentMyData(df,label_name, label_val,  augmenter, repetitions=1, samples=200):\n",
    "    \"\"\"Augments the data by generating new samples based on the given augmentation parameters.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame containing the data to be augmented.\n",
    "        label_name (str): The name of the label column in the DataFrame.\n",
    "        label_val: The value of the label for which augmentation is performed.\n",
    "        augmenter (nlpaug.augmenter.word.ContextualWordEmbsAug): The augmenter object used for augmentation.\n",
    "        repetitions (int, optional): The number of times each sentence is augmented. Defaults to 1.\n",
    "        samples (int, optional): The number of samples to be generated from the minority class. Defaults to 200.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The augmented DataFrame.\n",
    "    \"\"\"\n",
    "    augmented_texts = []\n",
    "    # select only the minority class samples\n",
    "    spam_df = df[df[label_name] == label_val].reset_index(drop=True) # removes unecessary index column\n",
    "    for i in tqdm(np.random.randint(0, len(spam_df), samples)):\n",
    "        # generating 'n_samples' augmented texts\n",
    "        for _ in range(repetitions):\n",
    "            # the random sentence chosen for augmentation\n",
    "            augmented_text= augment_sentence(spam_df['full_review'].iloc[i], augmenter)\n",
    "            \n",
    "            augmented_texts.append(augmented_text)\n",
    "    \n",
    "    data = {\n",
    "        label_name: label_val,\n",
    "        'full_review': augmented_texts\n",
    "    }\n",
    "    aug_df = pd.DataFrame(data)\n",
    "    df = shuffle(df.append(aug_df).reset_index(drop=True))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a very very cheaply home made commercial product.\n",
      "I really regret buying even it.\n",
      "Its a not really even worth the 2$. The reviews here are completely and fake.\n",
      "Dont sell buy.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' This is a very very cheaply home made commercial product. I really regret buying even it. Its a not really even worth the 2$. The reviews here are completely and fake. Dont sell buy.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"This is a very cheaply made product . I regret buying it.Its not even worth 2$. The reviews here are completely fake. Dont buy.\"\n",
    "augment_sentence(test, augmenter_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_management_df_1 = rating_management_df[['full_review', 'rating_managment_explicit_ohe']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6191\n",
       "1      97\n",
       "Name: rating_managment_explicit_ohe, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_management_df_1.rating_managment_explicit_ohe.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [4:06:39<00:00,  2.96s/it]    \n",
      "/var/folders/cg/93nnwcc94dd7ypq102y4db_c0000gn/T/ipykernel_47810/173017619.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = shuffle(df.append(aug_df).reset_index(drop=True))\n"
     ]
    }
   ],
   "source": [
    "rating_management_df_2=augmentMyData(rating_management_df_1,'rating_managment_explicit_ohe', 1, augmenter_insert, samples=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_management_df_2.to_csv('5000_training_rating_management_explicit.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5988\n",
       "1     300\n",
       "Name: disagreement_with_ratings_ohe, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disagreement_train_raw_df = pd.read_csv('/Users/kartikvijay/Documents/MADS/Thesis pt.2/augmentation/train_dataset_disagreement_with_ratings.csv')\n",
    "disagreement_train_raw_df.disagreement_with_ratings_ohe.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disagreement_with_ratings_ohe</th>\n",
       "      <th>full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>We purchased a number of these 20 pack Assorte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>We were a little concerned because a negative ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2018 compact pages are misaligned im using a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>cant understand WHY this thing is rated hi.It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I bought these for my kids to use on the white...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6283</th>\n",
       "      <td>0</td>\n",
       "      <td>Unfortunately my HP OfficeJet 8600 Plus reject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6284</th>\n",
       "      <td>0</td>\n",
       "      <td>This is the first book by David Sedaris I have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6285</th>\n",
       "      <td>0</td>\n",
       "      <td>I bought this for our RV medicine cabinet.. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6286</th>\n",
       "      <td>0</td>\n",
       "      <td>Misrepresentation of a product is a pet peeve ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6287</th>\n",
       "      <td>0</td>\n",
       "      <td>This is my first review. After I used it twice...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6288 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      disagreement_with_ratings_ohe  \\\n",
       "0                                 0   \n",
       "1                                 0   \n",
       "2                                 0   \n",
       "3                                 1   \n",
       "4                                 0   \n",
       "...                             ...   \n",
       "6283                              0   \n",
       "6284                              0   \n",
       "6285                              0   \n",
       "6286                              0   \n",
       "6287                              0   \n",
       "\n",
       "                                            full_review  \n",
       "0     We purchased a number of these 20 pack Assorte...  \n",
       "1     We were a little concerned because a negative ...  \n",
       "2     2018 compact pages are misaligned im using a f...  \n",
       "3     cant understand WHY this thing is rated hi.It ...  \n",
       "4     I bought these for my kids to use on the white...  \n",
       "...                                                 ...  \n",
       "6283  Unfortunately my HP OfficeJet 8600 Plus reject...  \n",
       "6284  This is the first book by David Sedaris I have...  \n",
       "6285  I bought this for our RV medicine cabinet.. Th...  \n",
       "6286  Misrepresentation of a product is a pet peeve ...  \n",
       "6287  This is my first review. After I used it twice...  \n",
       "\n",
       "[6288 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disagreement_train_raw_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [2:01:44<00:00,  2.92s/it]   \n",
      "/var/folders/cg/93nnwcc94dd7ypq102y4db_c0000gn/T/ipykernel_47810/173017619.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = shuffle(df.append(aug_df).reset_index(drop=True))\n"
     ]
    }
   ],
   "source": [
    "disagreement_train_augmented=augmentMyData(disagreement_train_raw_df,'disagreement_with_ratings_ohe', 1, augmenter_insert, samples=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "disagreement_train_augmented.to_csv('disagreement_with_ratings_train_augmented_dataset.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3500/3500 [2:31:55<00:00,  2.60s/it]  \n",
      "/var/folders/cg/93nnwcc94dd7ypq102y4db_c0000gn/T/ipykernel_47810/173017619.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = shuffle(df.append(aug_df).reset_index(drop=True))\n"
     ]
    }
   ],
   "source": [
    "disagreement_train_augmented_1=augmentMyData(disagreement_train_raw_df,'disagreement_with_ratings_ohe', 1, augmenter_insert, samples=3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "disagreement_train_augmented_1.to_csv('3500_augmented_disagreement_with_ratings.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
